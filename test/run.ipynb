{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import model as md\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [02:50<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3597877 3597877\n",
      "Creating yprofiles\n",
      "(3597877, 16) (3597877,) (3597877,)\n",
      "(3597877, 16) (3597877,)\n"
     ]
    }
   ],
   "source": [
    "# load example inputs and outputs\n",
    "inFilePath = \"/asic/projects/C/CMS_PIX_28/pixelAV_datasets/unshuffled_DO_NOT_DELETE/initial_studies/dataset14/unflipped\"\n",
    "yprofiles, ylocals, clslabels = ut.loadParquetData(inFilePath=inFilePath, qm_charge_levels = [400, 1600, 2400], qm_quant_values = [0, 1, 2, 3])\n",
    "print(yprofiles.shape, ylocals.shape, clslabels.shape)\n",
    "\n",
    "# assign to X, Y\n",
    "X = yprofiles\n",
    "Y = clslabels \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_912\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 58)                986       \n",
      "                                                                 \n",
      " batch_normalization_456 (B  (None, 58)                232       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " relu1 (Activation)          (None, 58)                0         \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 3)                 177       \n",
      "                                                                 \n",
      " linear (Activation)         (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1395 (5.45 KB)\n",
      "Trainable params: 1279 (5.00 KB)\n",
      "Non-trainable params: 116 (464.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"model_913\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input1 (InputLayer)         [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense1 (QDenseBatchnorm)    (None, 58)                1219      \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 58)                0         \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 3)                 177       \n",
      "                                                                 \n",
      " linear (Activation)         (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1396 (5.46 KB)\n",
      "Trainable params: 1279 (5.00 KB)\n",
      "Non-trainable params: 117 (472.00 Byte)\n",
      "_________________________________________________________________\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input1, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: dense1, layer type: QDenseBatchnorm, input shapes: [[None, 16]], output shape: [None, 58]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 58]], output shape: [None, 58]\n",
      "Layer name: dense2, layer type: QDense, input shapes: [[None, 58]], output shape: [None, 3]\n",
      "Layer name: linear, layer type: Activation, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input1, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: dense1, layer type: QDenseBatchnorm, input shapes: [[None, 16]], output shape: [None, 58]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 58]], output shape: [None, 58]\n",
      "Layer name: dense2, layer type: QDense, input shapes: [[None, 58]], output shape: [None, 3]\n",
      "Layer name: linear, layer type: Activation, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "Creating HLS model\n",
      "Writing HLS project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/asic/projects/C/CMS_PIX_28/testing/tools/venvs/p3.11.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./tmp/firmware/weights/b5_w5_b2_w2_pixel_bin.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "shape = 16 # y-profile ... why is this 16 and not 8?\n",
    "nb_classes = 3 # positive low pt, negative low pt, high pt\n",
    "first_dense = 58 # shape of first dense layer\n",
    "outDir = \"./tmp\"\n",
    "\n",
    "# keras model\n",
    "model_file = \"/fasic_home/gdg/research/projects/CMS_PIX_28/directional-pixel-detectors/multiclassifier/models/ds8l6_padded_noscaling_keras_d58model.h5\"\n",
    "model = md.CreateModel(shape, nb_classes, first_dense, model_file = model_file)\n",
    "\n",
    "# qkeras model\n",
    "qmodel_file = \"/fasic_home/gdg/research/projects/CMS_PIX_28/directional-pixel-detectors/multiclassifier/models/ds8l6_padded_noscaling_qkeras_foldbatchnorm_d58w4a8model.h5\"\n",
    "qmodel = md.CreateQModel(shape, model_file=qmodel_file)\n",
    "# generate hls model\n",
    "ut.gen_hls_model(qmodel, output_dir=outDir)\n",
    "# prepare weights for ASIC\n",
    "ut.prepareWeights(os.path.join(outDir, \"firmware/weights/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1757/1757 [==============================] - 2s 1ms/step\n",
      "Test loss: 2.291407585144043\n",
      "Test accuracy: 0.33843153715133667\n",
      "1757/1757 [==============================] - 3s 1ms/step\n",
      "Test loss: 1.6315134763717651\n",
      "Test accuracy: 0.33808133006095886\n"
     ]
    }
   ],
   "source": [
    "# Compute loss and accuracy manually\n",
    "def getLA(y, predictions, loss_fn, acc_metric=tf.keras.metrics.SparseCategoricalAccuracy()):\n",
    "    loss = loss_fn(y, predictions).numpy()\n",
    "    acc_metric.update_state(y, predictions)\n",
    "    accuracy = acc_metric.result().numpy()\n",
    "    print(f\"Test loss: {loss}\")\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "    return loss, accuracy\n",
    "\n",
    "# evaluating\n",
    "verbose = 1\n",
    "batch_size = 2048\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X, batch_size = batch_size, verbose=verbose)\n",
    "# predictions = np.argmax(predictions, axis=1)\n",
    "np.save(os.path.join(outDir, f\"keras_predictions.npy\"), predictions)\n",
    "model_loss, model_acc = getLA(Y, predictions, md.custom_loss_function)\n",
    "\n",
    "# make predictions\n",
    "qpredictions = qmodel.predict(X, batch_size = batch_size, verbose=verbose)\n",
    "# predictions = np.argmax(predictions, axis=1)\n",
    "np.save(os.path.join(outDir, f\"qkeras_predictions.npy\"), qpredictions)\n",
    "qmodel_loss, qmodel_acc = getLA(Y, qpredictions, md.custom_loss_function)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
