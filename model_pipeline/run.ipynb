{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import pandas as pd\n",
    "import model as md\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 58)                986       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 58)                232       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " relu1 (Activation)          (None, 58)                0         \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 3)                 177       \n",
      "                                                                 \n",
      " linear (Activation)         (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1395 (5.45 KB)\n",
      "Trainable params: 1279 (5.00 KB)\n",
      "Non-trainable params: 116 (464.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# configurations\n",
    "inFilePath = \"/asic/projects/C/CMS_PIX_28/pixelAV_datasets/unshuffled_DO_NOT_DELETE/initial_studies/dataset14/unflipped\"\n",
    "# inFilePath = \"/asic/projects/C/CMS_PIX_28/pixelAV_datasets/unshuffled_DO_NOT_DELETE/dataset_2sNoise/dataset_2sNoise_50x12P5_16x16_100e-sigma_parquets/unflipped\"\n",
    "# inFilePath = \"/asic/projects/C/CMS_PIX_28/pixelAV_datasets/unshuffled_DO_NOT_DELETE/dataset_2s16x16/dataset_2s_16x16_50x12P5_parquets/unflipped\"\n",
    "outDir=\"./tmp_21x13_newGGmodel9\"\n",
    "confs = [\n",
    "    # {\"qm_charge_levels\" : [400, 1600, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": True},\n",
    "#     {\"qm_charge_levels\" : [500, 1600, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": False},\n",
    "#     {\"qm_charge_levels\" : [600, 1600, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": False},\n",
    "    # {\"qm_charge_levels\" : [700, 1600, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": True},\n",
    "#     {\"qm_charge_levels\" : [800, 1600, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": False},\n",
    "#     {\"qm_charge_levels\" : [900, 1600, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": False},\n",
    "    {\"qm_charge_levels\" : [1000, 1600, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": True},\n",
    "#     {\"qm_charge_levels\" : [1100, 1600, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": False},\n",
    "#     {\"qm_charge_levels\" : [1200, 1600, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": False},\n",
    "#     {\"qm_charge_levels\" : [1300, 1600, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": False},\n",
    "#     {\"qm_charge_levels\" : [1600, 2000, 2400], \"qm_quant_values\" : [0, 1, 2, 3], \"zero_pad\": False},\n",
    "]\n",
    "\n",
    "\n",
    "# create model\n",
    "shape = 16 # y-profile ... why is this 16 and not 8?\n",
    "nb_classes = 3 # positive low pt, negative low pt, high pt\n",
    "first_dense = 58 # shape of first dense layer\n",
    "\n",
    "# keras model\n",
    "model_file = \"/fasic_home/gdg/research/projects/CMS_PIX_28/directional-pixel-detectors/multiclassifier/for_testing/models/ds8l6_padded_noscaling_keras_d58model_9.h5\"\n",
    "# model_file = \"/fasic_home/gdg/research/projects/CMS_PIX_28/directional-pixel-detectors/multiclassifier/models/ds8l6_padded_noscaling_keras_d58model.h5\"\n",
    "model = md.CreateModel(shape, nb_classes, first_dense, model_file = model_file)\n",
    "\n",
    "# qkeras model\n",
    "# qmodel_file = \"/fasic_home/gdg/research/projects/CMS_PIX_28/directional-pixel-detectors/multiclassifier/models/ds8l6_padded_noscaling_qkeras_foldbatchnorm_d58w4a8model.h5\"\n",
    "# qmodel_file = \"./16x16quantized/model.h5\"\n",
    "qmodel_file =  \"/fasic_home/gdg/research/projects/CMS_PIX_28/directional-pixel-detectors/multiclassifier/for_testing/models/ds8l6_padded_noscaling_qkeras_foldbatchnorm_d58w4a8model_9.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with configuration: {'qm_charge_levels': [1000, 1600, 2400], 'qm_quant_values': [0, 1, 2, 3], 'zero_pad': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/72 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:33<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299739,) (299739,) (299739,)\n",
      "299739\n",
      "Creating yprofiles\n"
     ]
    }
   ],
   "source": [
    "# load the parquet data, filter on y-profile bin, and quantize (all done in loadParquetData). Previously parqueted data was loaded and filtered on y-local in the next code-block. However this was moved to loadParquetData to avoid loading the entire dataset into memory and quantizing.\n",
    "for conf in confs:\n",
    "    if not os.path.exists(outDir):\n",
    "        os.makedirs(outDir)\n",
    "    print(f\"Running with configuration: {conf}\")\n",
    "    conf[\"qm\"] = ut.loadParquetData(inFilePath=inFilePath, qm_charge_levels = conf[\"qm_charge_levels\"], qm_quant_values = conf[\"qm_quant_values\"], zero_pad = conf[\"zero_pad\"],outDir=outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making compout of y-local subset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   done!\n"
     ]
    }
   ],
   "source": [
    "# Save asic compout\n",
    "outDict = conf[\"qm\"]\n",
    "y_local_bins = np.linspace(-8.1, 8.1, 13)\n",
    "bin_number = 6\n",
    "y_local_min, y_local_max = y_local_bins[bin_number], y_local_bins[bin_number + 1]\n",
    "# create compout of y-local subset\n",
    "if conf[\"qm\"][\"outDir\"] is not None:\n",
    "    compout_file_name = os.path.join(conf[\"qm\"][\"outDir\"], f'compouts_ylocal_{y_local_min:.2f}_{y_local_max:.2f}.csv')\n",
    "    ut.yprofileToCompoutWrite(conf[\"qm\"][\"yprofiles\"], compout_file_name)\n",
    "    outDict[\"compout_file_name\"] = compout_file_name\n",
    "\n",
    "for conf in confs:\n",
    "    conf[\"filtered_qm\"] = conf[\"qm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 58)                986       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 58)                232       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " relu1 (Activation)          (None, 58)                0         \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 3)                 177       \n",
      "                                                                 \n",
      " linear (Activation)         (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1395 (5.45 KB)\n",
      "Trainable params: 1279 (5.00 KB)\n",
      "Non-trainable params: 116 (464.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input1 (InputLayer)         [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense1 (QDenseBatchnorm)    (None, 58)                1219      \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 58)                0         \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 3)                 177       \n",
      "                                                                 \n",
      " linear (Activation)         (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1396 (5.46 KB)\n",
      "Trainable params: 1279 (5.00 KB)\n",
      "Non-trainable params: 117 (472.00 Byte)\n",
      "_________________________________________________________________\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input1, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: dense1, layer type: QDenseBatchnorm, input shapes: [[None, 16]], output shape: [None, 58]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 58]], output shape: [None, 58]\n",
      "Layer name: dense2, layer type: QDense, input shapes: [[None, 58]], output shape: [None, 3]\n",
      "Layer name: linear, layer type: Activation, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input1, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: dense1, layer type: QDenseBatchnorm, input shapes: [[None, 16]], output shape: [None, 58]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 58]], output shape: [None, 58]\n",
      "Layer name: dense2, layer type: QDense, input shapes: [[None, 58]], output shape: [None, 3]\n",
      "Layer name: linear, layer type: Activation, input shapes: [[None, 3]], output shape: [None, 3]\n",
      "Creating HLS model\n",
      "Writing HLS project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/asic/projects/C/CMS_PIX_28/testing/tools/venvs/p3.11.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./tmp_21x13_newGGmodel9/firmware/weights/b5_w5_b2_w2_pixel_bin.csv'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras model\n",
    "model = md.CreateModel(shape, nb_classes, first_dense, model_file = model_file)\n",
    "\n",
    "# qkeras model\n",
    "qmodel = md.CreateQModel(shape, model_file=qmodel_file)\n",
    "# generate hls model\n",
    "ut.gen_hls_model(qmodel, output_dir=outDir)\n",
    "# prepare weights for ASIC\n",
    "ut.prepareWeights(os.path.join(outDir, \"firmware/weights/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating keras model...\n",
      "147/147 [==============================] - 0s 1ms/step\n",
      "Finished evaluating keras model with loss: 0.5795490741729736, accuracy: 0.7296180725097656, predictions saved to ./tmp_21x13_newGGmodel9/1000_1600_2400/keras_predictions.npy\n",
      "\n",
      "Evaluating qkeras model...\n",
      "147/147 [==============================] - 0s 1ms/step\n",
      "Finished evaluating qkeras model with loss: 0.5326200127601624, accuracy: 0.7356967329978943, predictions saved to ./tmp_21x13_newGGmodel9/1000_1600_2400/qkeras_predictions.npy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute loss and accuracy manually\n",
    "def getLA(y, predictions, loss_fn, acc_metric=tf.keras.metrics.SparseCategoricalAccuracy()):\n",
    "    loss = loss_fn(y, predictions).numpy()\n",
    "    acc_metric.update_state(y, predictions)\n",
    "    accuracy = acc_metric.result().numpy()\n",
    "    return loss, accuracy\n",
    "\n",
    "# evaluating\n",
    "verbose = 1\n",
    "batch_size = 2048\n",
    "\n",
    "# loop over the confs\n",
    "for conf in confs:\n",
    "    \n",
    "    # make predictions\n",
    "    for m, name in zip([model, qmodel], [\"keras\", \"qkeras\"]):\n",
    "        print(f\"Evaluating {name} model...\")\n",
    "        conf[f\"{name}_predictions\"] = m.predict(conf[\"qm\"][\"yprofiles\"], batch_size = batch_size, verbose=verbose)\n",
    "        # predictions = np.argmax(predictions, axis=1)\n",
    "        predFileName = os.path.join(conf[\"qm\"][\"outDir\"], f\"{name}_predictions.npy\")\n",
    "        np.save(predFileName, conf[f\"{name}_predictions\"])\n",
    "        model_loss, model_acc = getLA(conf[\"qm\"][\"clslabels\"], conf[f\"{name}_predictions\"], md.custom_loss_function)\n",
    "        print(f\"Finished evaluating {name} model with loss: {model_loss}, accuracy: {model_acc}, predictions saved to {predFileName}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(13983,) and logits.shape=(1, 13983)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# predictions_npy = predictions.to_numpy()\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m model_loss, model_acc \u001b[38;5;241m=\u001b[39m \u001b[43mgetLA\u001b[49m\u001b[43m(\u001b[49m\u001b[43md28_test_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_loss_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished evaluating qmodel with loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# def getLA(y, predictions, loss_fn, acc_metric=tf.keras.metrics.SparseCategoricalAccuracy()):\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#     loss = loss_fn(y, predictions).numpy()\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     acc_metric.update_state(y, predictions)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     accuracy = acc_metric.result().numpy()\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#     return loss, accuracy\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[57], line 3\u001b[0m, in \u001b[0;36mgetLA\u001b[0;34m(y, predictions, loss_fn, acc_metric)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetLA\u001b[39m(y, predictions, loss_fn, acc_metric\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy()):\n\u001b[0;32m----> 3\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      4\u001b[0m     acc_metric\u001b[38;5;241m.\u001b[39mupdate_state(y, predictions)\n\u001b[1;32m      5\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m acc_metric\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/asic/projects/C/CMS_PIX_28/dshekar/filter/model_pipeline/model.py:106\u001b[0m, in \u001b[0;36mcustom_loss_function\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    103\u001b[0m y_true \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(mask, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# compute loss\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_categorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# mask loss\u001b[39;00m\n\u001b[1;32m    109\u001b[0m loss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m mask\n",
      "File \u001b[0;32m/asic/projects/C/CMS_PIX_28/testing/tools/venvs/p3.11.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/asic/projects/C/CMS_PIX_28/testing/tools/venvs/p3.11.11/lib/python3.11/site-packages/keras/src/losses.py:2354\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, axis, ignore_class)\u001b[0m\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[1;32m   2305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.metrics.sparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.losses.sparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2310\u001b[0m     y_true, y_pred, from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, ignore_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2311\u001b[0m ):\n\u001b[1;32m   2312\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes the sparse categorical crossentropy loss.\u001b[39;00m\n\u001b[1;32m   2313\u001b[0m \n\u001b[1;32m   2314\u001b[0m \u001b[38;5;124;03m    Standalone usage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2352\u001b[0m \u001b[38;5;124;03m      Sparse categorical crossentropy loss value.\u001b[39;00m\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_categorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2355\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2356\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2360\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/asic/projects/C/CMS_PIX_28/testing/tools/venvs/p3.11.11/lib/python3.11/site-packages/keras/src/backend.py:5766\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis, ignore_class)\u001b[0m\n\u001b[1;32m   5762\u001b[0m         res \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msparse_softmax_cross_entropy_with_logits(\n\u001b[1;32m   5763\u001b[0m             labels\u001b[38;5;241m=\u001b[39mtarget, logits\u001b[38;5;241m=\u001b[39moutput\n\u001b[1;32m   5764\u001b[0m         )\n\u001b[1;32m   5765\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5766\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_softmax_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\n\u001b[1;32m   5768\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5771\u001b[0m     res_shape \u001b[38;5;241m=\u001b[39m cast(output_shape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(13983,) and logits.shape=(1, 13983)"
     ]
    }
   ],
   "source": [
    "test_dir = \"/fasic_home/gdg/research/projects/CMS_PIX_28/directional-pixel-detectors/multiclassifier/data/ds8_only/dec6_ds8_quant/QuantizedInputTestSetLocal6.csv\"\n",
    "test_labels = \"/fasic_home/gdg/research/projects/CMS_PIX_28/directional-pixel-detectors/multiclassifier/data/ds8_only/dec6_ds8_quant/TestSetLabelLocal6.csv\"\n",
    "data = pd.read_csv(test_dir)\n",
    "data_padded = pd.concat([data, pd.DataFrame(0, index=data.index, columns=['13', '14', '15'])], axis=1)\n",
    "labels = pd.read_csv(test_labels, header=None, skiprows=1)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "ds8_test = data_padded.to_numpy()\n",
    "# d28_test_labels = labels.to_numpy()\n",
    "d28_test_labels = labels[0].to_numpy()  # Assuming labels are in the first column\n",
    "# Ensure labels are integers\n",
    "d28_test_labels = d28_test_labels.astype(int)\n",
    "\n",
    "# Get predictions\n",
    "predictions = qmodel.predict(ds8_test, batch_size=batch_size, verbose=verbose)\n",
    "# print(predictions)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "# predictions_npy = predictions.to_numpy()\n",
    "\n",
    "model_loss, model_acc = getLA(d28_test_labels, predictions, md.custom_loss_function)\n",
    "print(f\"Finished evaluating qmodel with loss: {model_loss}, accuracy: {model_acc}.\")\n",
    "\n",
    "\n",
    "\n",
    "# def getLA(y, predictions, loss_fn, acc_metric=tf.keras.metrics.SparseCategoricalAccuracy()):\n",
    "#     loss = loss_fn(y, predictions).numpy()\n",
    "#     acc_metric.update_state(y, predictions)\n",
    "#     accuracy = acc_metric.result().numpy()\n",
    "#     return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.11 64-bit",
   "language": "python",
   "name": "python3111164bitad9897ed63ca4115b301c82efce97f24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
